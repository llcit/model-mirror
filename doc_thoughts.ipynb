{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeb Lakey\n",
    "\n",
    "Dr. Richard Medina\n",
    "\n",
    "Model in the Mirror"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the documentation/thought process during the Model in the Mirror project running from July 20 - August 25 2023. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First File: apitest.py\n",
    "Used to get used to certain parts of the openai library and to test the API call. Worked correctly. References trainingdata.jsonl and validationfile.jsonl, which were empty JSON Lines files that the fine-tuning training draws from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeb Lakey, 07.21.23, Model in the Mirror w/ Dr. Richard Medina\n",
    "import openai\n",
    "import json\n",
    "\n",
    "APIKEY = 'samplekey'\n",
    "openai.api_key = APIKEY\n",
    "trainingfile = \"trainingdata.jsonl\"\n",
    "validationfile = \"validationdata.jsonl\"\n",
    "\n",
    "response = openai.Completion.create(\n",
    "  engine=\"text-davinci-003\",\n",
    "  prompt=\"Who won the super bowl in 2015?\",\n",
    "  max_tokens=30\n",
    ")\n",
    "print(response)\n",
    "#Response: The New England Patriots won the Super Bowl in 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next part was generating a bank of questions and answers to be used as a control group to compare to the responses of the fine tuned model we will be creating later. The topic that was came up with was Astronomy, and the difficulty levels used were divided into Elementary, Intermediate, and Advanced. Responses were generated below using GPT 3.5.\n",
    "\n",
    "5 different question structures were utilized per reading level. This was to test if the way in which the question was asked impacted prompt quality. It didn't, with the responses generated even being the exact same in some cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1: Elementary\n",
    "\n",
    "<br>TC1\n",
    "<br>Q: \"write a 25-word, elementary level passage about astronomy in english\" \n",
    "<br>A: \"In astronomy, we study space and everything in it. We learn about stars, planets, and the moon. It's like exploring a vast cosmic playground!\"\n",
    "<br>Word Count: 24\n",
    "<br>TC2\n",
    "<br>Q: \"write an elementary level english passage about astronomy that is 25 words long\"\n",
    "<br>A: \"Astronomy is all about space. We learn about stars, planets, and the moon. It's exciting to discover the secrets of the universe!\"\n",
    "<br>Word Count: 22\n",
    "<br>TC3\n",
    "<br>Q: \"write a 25-word, elementary level passage in english about astronomy\"\n",
    "<br>A: \"Astronomy is about space and stars. We study planets and the moon. It's fun to learn about the universe and its wonders!\"\n",
    "<br>Word Count: 22\n",
    "<br>TC4\n",
    "<br>Q: \"write a passage with these parameters: LENGTH: 25 words LANGUAGE COMPLEXITY: Elementary TOPIC: Astronomy LANGUAGE: English\"\n",
    "<br>A: \"Astronomy is about space and stars. We study planets and the moon. It's fun to learn about the universe and its wonders!\"\n",
    "<br>Word Count: 22\n",
    "<br>TC5\n",
    "<br>Q: \"write a passage with these parameters: LENGTH: 25 words READING LEVEL: Elementary TOPIC: Astronomy LANGUAGE: English\"\n",
    "<br>A: \"Explore the sky's mysteries in astronomy. Stars, planets, and the moon amaze us. Join the cosmic journey, learning the wonders above.\"\n",
    "<br>Word Count: 21\n",
    "\n",
    "2: Intermediate\n",
    "\n",
    "<br>TC1\n",
    "<br>Q: \"write a 25-word, intermediate level passage about astronomy in english\"\n",
    "<br>A: \"Astronomy is the study of celestial objects like stars, planets, and galaxies. It explores the universe's origins, evolution, and phenomena like black holes and supernovae.\"\n",
    "<br>Word Count: 25\n",
    "<br>TC2\n",
    "<br>Q: \"write an intermediate level english passage about astronomy that is 25 words long\"\n",
    "<br>A: \"Astronomy delves into celestial wonders - stars, planets, galaxies. We explore the universe's mysteries: dark matter, cosmic evolution, and the search for extraterrestrial life.\"\n",
    "<br>Word Count: 23\n",
    "<br>TC3\n",
    "<br>Q: \"write a 25-word, intermediate level passage in english about astronomy\"\n",
    "<br>A: \"Astronomy uncovers celestial marvels - stars, planets, galaxies. We explore cosmic phenomena: black holes, dark matter, and the quest for extraterrestrial intelligence.\"\n",
    "<br>Word Count: 21\n",
    "<br>TC4\n",
    "<br>Q: \"write a passage with these parameters: LENGTH: 25 words LANGUAGE COMPLEXITY: Intermediate TOPIC: Astronomy LANGUAGE: English\"\n",
    "<br>A: \"Astronomy, a profound cosmic pursuit, explores celestial marvels: stars, planets, galaxies. Unravel enigmasâ€”black holes, dark matter, and the search for life beyond Earth. Embark on astronomical wonders!\"\n",
    "<br>Word Count: 28\n",
    "<br>A: \"Astronomy, the study of celestial objects and phenomena, unveils the wonders of the universe. From stars to galaxies, it ignites curiosity and expands human understanding.\"\n",
    "<br>Word Count: 25\n",
    "<br>TC5\n",
    "<br>Q: \"write a passage with these parameters: LENGTH: 25 words READING LEVEL: Intermediate TOPIC: Astronomy LANGUAGE: English\"\n",
    "<br>A: \"Astronomy unlocks the cosmos. Discover stars, planets, and galaxies. Unravel mysteries like black holes and dark matter. The universe awaits exploration!\"\n",
    "<br>Word Count: 21\n",
    "\n",
    "3: Advanced\n",
    "\n",
    "<br>TC1\n",
    "<br>Q: \"write a 25-word, advanced level passage about astronomy in english\"\n",
    "<br>A: \"Astronomy, the venerable science of cosmic exploration, delves into the intricate workings of celestial entities, unearthing cosmic origins and probing the enigmas of the universe.\"\n",
    "<br>Word Count: 25\n",
    "<br>TC2\n",
    "<br>Q: \"write an advanced level english passage about astronomy that is 25 words long\"\n",
    "<br>A: \"Astronomy, an intricate cosmic pursuit, unravels celestial origins, explores galaxies, and illuminates the universe's enigmatic wonders, expanding our cosmic consciousness.\"\n",
    "<br>Word Count: 20\n",
    "<br>TC3\n",
    "<br>Q: \"write a 25-word, advanced level passage in english about astronomy\"\n",
    "<br>A: \"Astronomy, the profound study of celestial phenomena, unveils cosmic mysteries, such as black holes and dark matter, reshaping our perception of the cosmos.\"\n",
    "<br>Word Count: 23\n",
    "<br>TC4\n",
    "<br>Q: \"write a passage with these parameters: LENGTH: 25 words LANGUAGE COMPLEXITY: Advanced TOPIC: Astronomy LANGUAGE: English\"\n",
    "<br>A: \"In the realm of astronomy, celestial symphonies play out as galaxies collide, birthing quasars that illuminate the cosmic tapestry, revealing its enigmatic dance of dark matter and energy.\"\n",
    "<br>Word Count: 28\n",
    "<br>TC5\n",
    "<br>Q: \"write a passage with these parameters: LENGTH: 25 words READING LEVEL: Advanced TOPIC: Astronomy LANGUAGE: English\"\n",
    "<br>A: \"Amid the vast expanse of the cosmos, astronomy beckons explorers to decipher the secrets of celestial realms, igniting wonder and enlightening humanity's cosmic journey.\"\n",
    "<br>\n",
    "Word Count: 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it was at this stage when we realized that the models available for fine tuning were very far away from actually being able to be used for text generation. It was at this point that we re-evaluated our focus and turned towards using GPT 3.5 to generate prompts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyMuPDF was used to scrape a pdf file. The contents of a couple pages of this pdf was then fed into GPT to create 3 100-word passages from the contents it was given."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeb Lakey, 07.24.23, Model in the Mirror w/ Dr. Richard Medina\n",
    "\n",
    "import fitz\n",
    "import openai\n",
    "\n",
    "APIKEY = 'samplekey'\n",
    "openai.api_key = APIKEY\n",
    "\n",
    "doc = fitz.open(\"sample.pdf\")\n",
    "\n",
    "instruction = 'You are a language teacher tasked with developing 100 word passages for the purpose of language instruction. These passages will be used to test language learners with their corresponding literacy levels. '\n",
    "text = 'QUERY: write 3 100-word summaries in english about this exerpt: '\n",
    "\n",
    "for page in doc.pages(2,6,1):\n",
    "    extract = page.get_text()\n",
    "    text += extract\n",
    "doc.close()\n",
    "\n",
    "def returnPrompts(sinput, cinput):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": sinput},\n",
    "        {\"role\": \"user\", \"content\": cinput}],\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "    )\n",
    "    reply = response['choices'][0]['message']['content']\n",
    "    return reply\n",
    "\n",
    "reply = returnPrompts(instruction, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This worked well, but the passages generated still need to be separated into difficulty levels. NOTE: Tried to change wording to summaries, passages worked better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I received definitions of each of the language levels from another intern at the CLT, Ashley Nichols. They are shown here:\n",
    "\n",
    "Beginner:\n",
    "\"Beginner means that the language used has short sentences, \n",
    "simple grammar patterns, and uses vocabulary words of high \n",
    "frequency.\";\n",
    "\n",
    "Intermediate:\n",
    "\"Intermediate means that the language used has somewhat complex \n",
    "grammar, more infrequent vocabulary, \n",
    "and longer sentences, but does not contain extremely \n",
    "complex grammar, jargon, or complex sentences.\";\n",
    "\n",
    "Advanced:\n",
    "\"Advanced means that the language used has complex grammar, \n",
    "contains infrequent vocabulary words and jargon, and has \n",
    "lengthy sentences.\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yielded acceptable results for the current stage of the project when tested on the online chatbot version of gpt3.5. I then moved on to creating another system prompt + function definition for the simplification/modification process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeb Lakey, 07.25.23, Model in the Mirror w/ Dr. Richard Medina\n",
    "intro = 'You are a writer tasked with modifying a set of passages to a set of instructions. These are the instructions: '\n",
    "beginnerInstruction = 'Simplify the following passages to beginner level, which means the language used has short sentences, simple grammar patterns, and uses vocabulary words of high frequency.'\n",
    "intermediateInstruction = 'Modify the following passages to intermediate level, which means that the language used has somewhat complex grammar, more infrequent vocabulary, and longer sentences, but does not contain extremely complex grammar, jargon, or complex sentences.'\n",
    "advancedInstruction = 'Modify the following passages to advanced level, which means that the language used has complex grammar, contains infrequent vocabulary words and jargon, and has lengthy sentences.'\n",
    "\n",
    "#have some form of user input here for choice of instruction type\n",
    "\n",
    "userInput = intro + beginnerInstruction\n",
    "\n",
    "def simplifyReplies(sysinput, cinput):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": sysinput},\n",
    "        {\"role\": \"user\", \"content\": cinput}],\n",
    "        max_tokens=1000,\n",
    "        temperature=0,\n",
    "    )\n",
    "    passage = response['choices'][0]['message']['content']\n",
    "    return passage\n",
    "\n",
    "finalPassages = simplifyReplies(userInput, reply) #reply is the reply that the first api call produced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This yielded 3 passages that were at an acceptable level of difficulty at the beginner level. Next was to write a simple bit of code to write the user prompts and the corresponding content generated to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('FULLRUNTEST.txt', 'a') as f:\n",
    "    f.write('\\n\\nSYSTEM PROMPT: ' + instruction + '\\n\\n')\n",
    "    f.write('QUERY: write 3 200-word passages in english about this exerpt: \\n\\n')\n",
    "    f.write('TEXT INPUT: ' + text + '\\n\\n')\n",
    "    f.write('RESPONSE: ' + reply + '\\n\\n')\n",
    "    f.write('QUERY 2: ' + userInput + '\\n\\n')\n",
    "    f.write('Final Passsages' + finalPassages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also did some cleaning up of the initial code and added some exception handling in the pdf reading section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeb Lakey, 07.25.23, Model in the Mirror w/ Dr. Richard Medina\n",
    "text = 'QUERY: write 3 120-word passages in english about this exerpt: '\n",
    "\n",
    "try:\n",
    "    doc = fitz.open(\"sample.pdf\")\n",
    "except SystemError:\n",
    "        print(\"error opening pdf\")\n",
    "else:\n",
    "    for page in doc.pages(2,doc.page_count,1):\n",
    "        if(len(text) < 10000):\n",
    "            extract = page.get_text()\n",
    "            text += extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next step was creating a database for the prompts to be stored in after processing. This was done using a simple dictionary with keys such as Culture, Sports, and Astronomy. The value corresponding to these keys is a Python list that holds the prompts. The dictionary is stored in a json and accessed using load/dump. This was tested in a separate file before being implimented in the main script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeb Lakey, 07.25.23, Model in the Mirror w/ Dr. Richard Medina\n",
    "import json\n",
    "\n",
    "with open(\"promptdatabase.json\", \"r\") as read_file:\n",
    "    data = json.load(read_file)\n",
    "\n",
    "data[\"Culture\"].append(\"New Prompt\")\n",
    "data[\"Math\"].append(\"New Prompt\")\n",
    "data[\"Science\"].append(\"New Prompt\")\n",
    "data[\"Language\"].append(\"New Prompt\")\n",
    "\n",
    "with open(\"promptdatabase.json\", \"w\") as write_file:\n",
    "    json.dump(data, write_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorization is fairly simple. I set up the prompt for the simplifyReplies function to include a delimiter between the passages, separated them using split(), and placed the now separate passages into an array. To do the categorizing, I set up another API call and had it choose a category from preexisting choices I put into the prompt. I then created a for loop, called the classification function, placed the response into a string, and used conditional statements with the \"in\" keyword to choose a dictionary category. It then appends the prompt to the list and dumps the results back into the json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeb Lakey, 07.26.23, Model in the Mirror w/ Dr. Richard Medina\n",
    "arr = finalPassages.split(\"####\")\n",
    "\n",
    "def classifyPassages(cinput):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "        {\"role\": \"user\", \"content\": cinput}],\n",
    "        max_tokens=100,\n",
    "        temperature=0,\n",
    "    )\n",
    "    passage = response['choices'][0]['message']['content']\n",
    "    return passage\n",
    "\n",
    "with open(\"promptdatabase.json\", \"r\") as rf:\n",
    "    dict = json.load(rf)\n",
    "\n",
    "for i in range(len(arr)):\n",
    "    pintro = 'QUERY: Classify this passage as one of the following - Culture, Astronomy, School, Food, Sports, or Other' + arr[i]\n",
    "    classification = classifyPassages(pintro)\n",
    "    if 'Culture' in classification:\n",
    "        dict[\"Culture\"].append(arr[i])\n",
    "    elif 'Astronomy' in classification:\n",
    "        dict[\"Astronomy\"].append(arr[i])\n",
    "    elif 'School' in classification:\n",
    "        dict[\"School\"].append(arr[i])\n",
    "    elif 'Food' in classification:\n",
    "        dict[\"Food\"].append(arr[i])\n",
    "    elif 'Sports' in classification:\n",
    "        dict[\"Sports\"].append(arr[i])\n",
    "    else:\n",
    "        dict[\"Other\"].append(arr[i])\n",
    "\n",
    "with open(\"promptdatabase.json\", \"w\") as wf:\n",
    "    json.dump(dict, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another script was also written that takes the input from a smaller paragraph of text and generates passages from them. This was essentially just changing the prompt, but I set it up to read from a txt file for easier use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeb Lakey, 07.26.23, Model in the Mirror w/ Dr. Richard Medina\n",
    "import openai\n",
    "\n",
    "APIKEY = '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'\n",
    "openai.api_key = APIKEY\n",
    "\n",
    "initInstruction = 'You are a writer tasked with creating 5 120-word passages based on a paragraph of source material. You may draw from other sources in this writing.'\n",
    "\n",
    "with open('paragraphmaterial.txt', 'r') as f:\n",
    "    cinput = f.read()\n",
    "\n",
    "cinput = 'QUERY: Write 5 unique 120-word passages based loosely on this paragraph: ' + cinput\n",
    "\n",
    "def returnPrompts(sysinput, cinput):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "        {\"role\": \"system\", \"content\": sysinput},\n",
    "        {\"role\": \"user\", \"content\": cinput}],\n",
    "        max_tokens=1000,\n",
    "        temperature=0.9,\n",
    "        presence_penalty = 0.8\n",
    "    )\n",
    "    reply = response['choices'][0]['message']['content']\n",
    "    return reply\n",
    "\n",
    "passages = returnPrompts(initInstruction, cinput)\n",
    "\n",
    "with open('paragenresponse.txt', 'a') as f:\n",
    "    f.write('\\n\\nSYSTEM PROMPT: ' + initInstruction + '\\n\\n')\n",
    "    f.write(cinput + '\\n\\n')\n",
    "    f.write('TEXT INPUT: ' + passages + '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point, two alternate ways of developing passages were created. Now, it was important to take both of these and combine them to form a script that optimally generated passages that was also easy to understand sequentially. Multiple edits were made and a completely new script was created. The API Key was moved to an environmental variable, the translation was moved over to the simplification rather than happening initially, and the categorization and storing into the database was done within the same step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Zeb Lakey, 08.04.23, Model in the Mirror w/ Dr. Richard Medina\n",
    "basePassages = [\"Passage A\", \"Passage B\"]\n",
    "basecinput = \"develop a prompt blah blah\"\n",
    "for i in range(len(basePassages)):\n",
    "    finalPassages.append(simplifyReplies(userInput,(basecinput + basePassages[i])))\n",
    "    finalPassages[i] = ''.join(finalPassages.splitlines())\n",
    "    print(finalPassages[i])\n",
    "    pintro = 'QUERY: Classify this passage in english as one of the following - Culture, Astronomy, School, Food, Sports, or Other. Give a one word response. Pick ONLY from these categories.' + finalPassages[i]\n",
    "    classification = classifyPassages(pintro)\n",
    "    print(classification)\n",
    "    if 'Culture' in classification:\n",
    "        dict[\"Culture\"].append(finalPassages[i])\n",
    "    elif 'Astronomy' in classification:\n",
    "        dict[\"Astronomy\"].append(finalPassages[i])\n",
    "    elif 'School' in classification:\n",
    "        dict[\"School\"].append(finalPassages[i])\n",
    "    elif 'Food' in classification:\n",
    "        dict[\"Food\"].append(finalPassages[i])\n",
    "    elif 'Sports' in classification:\n",
    "        dict[\"Sports\"].append(finalPassages[i])\n",
    "    else:\n",
    "        dict[\"Other\"].append(finalPassages[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we felt as though it was best to move on to the c-test generation. These tests were done in english using the NLTK, which is a language processing platform for Python. After some initial hiccups getting everything set up, a very early iteration of the C-test was developed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "text = \"We need to learn more about intersectionality to really understand it. We can't just have simple ideas about what it means. We need to look at its history and think about it carefully. By doing this, we can see how important intersectionality is and how it can help us make things better.\"\n",
    "lemm = nltk.WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "ctestfinal = \"\"\n",
    "\n",
    "def convert(input):\n",
    "    base = \"\"\n",
    "    print(str(input) + '\\n')\n",
    "    for i in range(len(input)):\n",
    "        if (i == 0):\n",
    "            base += (' ' + input[i] + ' ')\n",
    "        elif (input[i] != input[-1]) and (\"'\" in input[i+1]):\n",
    "            base += input[i]\n",
    "        elif (input[i] != input[-1]) and (',' in input[i+1]):\n",
    "            base += input[i]\n",
    "        elif (input[i] != input[-1]) and ('.' in input[i+1]):\n",
    "            base += input[i]\n",
    "        elif (input[i] != input[-1]):\n",
    "            base += (input[i] + ' ')\n",
    "        else:\n",
    "            base += input[i]\n",
    "    return base\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words[1] = lemm.lemmatize(words[1])\n",
    "    newword, trash = divmod(len(words[1]), 2)\n",
    "    words[1] = words[1][:newword + trash]\n",
    "    words[1] += (\"_\" * newword)\n",
    "    sentences[i] = words\n",
    "    conversion = convert(sentences[i])\n",
    "    ctestfinal += conversion\n",
    "\n",
    "ctestfinal = ctestfinal.lstrip(\" \")\n",
    "print(ctestfinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This snippet uses NLTK to separate the string into sentences, and then further separates each sentence into a list of words. The second word of each list is modified using divmod, and is split in half. If the word has an odd number of letters, more letters are kept than taken away. The convert method at the top is to reconstruct the string for printing purposes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
